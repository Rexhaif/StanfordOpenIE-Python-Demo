{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure that your java version >= 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_212\"\r\n",
      "OpenJDK Runtime Environment (build 1.8.0_212-b04)\r\n",
      "OpenJDK 64-Bit Server VM (build 25.212-b04, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Stanford CoreNLP (375mb, quite heavy) and unzip it\n",
    "if you just wanna try openie, skip to python part and replace https://localhost:9000 with http://corenlp.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-30 16:35:43--  http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip [following]\n",
      "--2019-06-30 16:35:44--  https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 393239982 (375M) [application/zip]\n",
      "Saving to: ‘stanford-corenlp-full-2018-10-05.zip’\n",
      "\n",
      "stanford-corenlp-fu 100%[===================>] 375,02M   602KB/s    in 11m 11s \n",
      "\n",
      "2019-06-30 16:46:56 (572 KB/s) - ‘stanford-corenlp-full-2018-10-05.zip’ saved [393239982/393239982]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  stanford-corenlp-full-2018-10-05.zip\n",
      "   creating: ./stanford-corenlp-full-2018-10-05/\n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/xom-1.2.10-src.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/CoreNLP-to-HTML.xsl  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/README.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jollyday-0.4.9-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/LIBRARY-LICENSES  \n",
      "   creating: ./stanford-corenlp-full-2018-10-05/sutime/\n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/sutime/british.sutime.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/sutime/defs.sutime.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/sutime/spanish.sutime.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/sutime/english.sutime.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/sutime/english.holidays.sutime.txt  \n",
      " extracting: ./stanford-corenlp-full-2018-10-05/ejml-0.23-src.zip  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/input.txt.xml  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/build.xml  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/pom.xml  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-javadoc.jar  \n",
      "   creating: ./stanford-corenlp-full-2018-10-05/tokensregex/\n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/tokensregex/color.input.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/tokensregex/retokenize.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/tokensregex/color.properties  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/tokensregex/color.rules.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/javax.json-api-1.0-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jaxb-api-2.4.0-b180830.0359-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-models.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/protobuf.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/javax.activation-api-1.2.0.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/StanfordDependenciesManual.pdf  \n",
      "   creating: ./stanford-corenlp-full-2018-10-05/patterns/\n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/patterns/example.properties  \n",
      " extracting: ./stanford-corenlp-full-2018-10-05/patterns/otherpeople.txt  \n",
      " extracting: ./stanford-corenlp-full-2018-10-05/patterns/goldplaces.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/patterns/stopwords.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/patterns/presidents.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/patterns/names.txt  \n",
      " extracting: ./stanford-corenlp-full-2018-10-05/patterns/places.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/patterns/goldnames.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/slf4j-simple.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/input.txt  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/joda-time.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/xom.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/StanfordCoreNlpDemo.java  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jaxb-core-2.3.0.1.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/RESOURCE-LICENSES  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/javax.activation-api-1.2.0-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/slf4j-api.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/pom-java-11.xml  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/ejml-0.23.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/javax.json.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/Makefile  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/corenlp.sh  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/joda-time-2.9-sources.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jaxb-api-2.4.0-b180830.0359.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jollyday.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/ShiftReduceDemo.java  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/jaxb-impl-2.4.0-b180830.0438.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2.jar  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/SemgrexDemo.java  \n",
      "  inflating: ./stanford-corenlp-full-2018-10-05/LICENSE.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip stanford-corenlp-full-2018-10-05.zip -d ./ && mv ./stanford-corenlp-full-2018-10-05 ./corenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch corenlp server in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('cd ./corenlp/ && java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if it works (should return some json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"sentences\": [\r\n",
      "    {\r\n",
      "      \"index\": 0,\r\n",
      "      \"tokens\": [\r\n",
      "        {\r\n",
      "          \"index\": 1,\r\n",
      "          \"word\": \"The\",\r\n",
      "          \"originalText\": \"The\",\r\n",
      "          \"characterOffsetBegin\": 0,\r\n",
      "          \"characterOffsetEnd\": 3,\r\n",
      "          \"pos\": \"DT\",\r\n",
      "          \"before\": \"\",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 2,\r\n",
      "          \"word\": \"quick\",\r\n",
      "          \"originalText\": \"quick\",\r\n",
      "          \"characterOffsetBegin\": 4,\r\n",
      "          \"characterOffsetEnd\": 9,\r\n",
      "          \"pos\": \"JJ\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 3,\r\n",
      "          \"word\": \"brown\",\r\n",
      "          \"originalText\": \"brown\",\r\n",
      "          \"characterOffsetBegin\": 10,\r\n",
      "          \"characterOffsetEnd\": 15,\r\n",
      "          \"pos\": \"JJ\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 4,\r\n",
      "          \"word\": \"fox\",\r\n",
      "          \"originalText\": \"fox\",\r\n",
      "          \"characterOffsetBegin\": 16,\r\n",
      "          \"characterOffsetEnd\": 19,\r\n",
      "          \"pos\": \"NN\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 5,\r\n",
      "          \"word\": \"jumped\",\r\n",
      "          \"originalText\": \"jumped\",\r\n",
      "          \"characterOffsetBegin\": 20,\r\n",
      "          \"characterOffsetEnd\": 26,\r\n",
      "          \"pos\": \"VBD\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 6,\r\n",
      "          \"word\": \"over\",\r\n",
      "          \"originalText\": \"over\",\r\n",
      "          \"characterOffsetBegin\": 27,\r\n",
      "          \"characterOffsetEnd\": 31,\r\n",
      "          \"pos\": \"IN\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 7,\r\n",
      "          \"word\": \"the\",\r\n",
      "          \"originalText\": \"the\",\r\n",
      "          \"characterOffsetBegin\": 32,\r\n",
      "          \"characterOffsetEnd\": 35,\r\n",
      "          \"pos\": \"DT\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 8,\r\n",
      "          \"word\": \"lazy\",\r\n",
      "          \"originalText\": \"lazy\",\r\n",
      "          \"characterOffsetBegin\": 36,\r\n",
      "          \"characterOffsetEnd\": 40,\r\n",
      "          \"pos\": \"JJ\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \" \"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 9,\r\n",
      "          \"word\": \"dog\",\r\n",
      "          \"originalText\": \"dog\",\r\n",
      "          \"characterOffsetBegin\": 41,\r\n",
      "          \"characterOffsetEnd\": 44,\r\n",
      "          \"pos\": \"NN\",\r\n",
      "          \"before\": \" \",\r\n",
      "          \"after\": \"\"\r\n",
      "        },\r\n",
      "        {\r\n",
      "          \"index\": 10,\r\n",
      "          \"word\": \".\",\r\n",
      "          \"originalText\": \".\",\r\n",
      "          \"characterOffsetBegin\": 44,\r\n",
      "          \"characterOffsetEnd\": 45,\r\n",
      "          \"pos\": \".\",\r\n",
      "          \"before\": \"\",\r\n",
      "          \"after\": \"\"\r\n",
      "        }\r\n",
      "      ]\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl --data 'The quick brown fox jumped over the lazy dog.' 'http://localhost:9000/?properties={%22annotators%22%3A%22tokenize%2Cssplit%2Cpos%22%2C%22outputFormat%22%3A%22json%22}' -o -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Py-CoreNLP lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycorenlp\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/40/e74eb4fc7906d630b73a84c9ae9d824f694bd4c5a1d727b8e18beadff613/pycorenlp-0.3.0.tar.gz\n",
      "Collecting requests (from pycorenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 810kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests->pycorenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.6MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/rexhaif/miniconda3/envs/base-jp/lib/python3.7/site-packages (from requests->pycorenlp) (2019.6.16)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->pycorenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests->pycorenlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pycorenlp\n",
      "  Building wheel for pycorenlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/rexhaif/.cache/pip/wheels/fb/e9/2f/767a7b5f2e82d587a36143c04a21839b4b14bebfb89410d2d5\n",
      "Successfully built pycorenlp\n",
      "Installing collected packages: idna, urllib3, chardet, requests, pycorenlp\n",
      "Successfully installed chardet-3.0.4 idna-2.8 pycorenlp-0.3.0 requests-2.22.0 urllib3-1.25.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pycorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('Pusheen and Smitha walked along the beach. '\n",
    "        'Pusheen wanted to surf, but fell off the surfboard. '\n",
    "        'The quick brown fox jumped over the lazy dog. '\n",
    "        'Barack Obama was born in Hawaii.  '\n",
    "        'He was elected president in 2008. ')\n",
    "output = nlp.annotate(text, properties = {\n",
    "  'annotators': 'tokenize,ssplit,pos,depparse,natlog,openie',\n",
    "  'outputFormat': 'json'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Sentence: Pusheen and Smitha walked along the beach .\n",
      "--------------------\n",
      "IE triplets:\n",
      "--------------------\n",
      "      Pusheen        ->  walked along  -> beach\n",
      "       Smitha        ->  walked along  -> beach\n",
      "==================================================\n",
      "Sentence: Pusheen wanted to surf , but fell off the surfboard .\n",
      "--------------------\n",
      "IE triplets:\n",
      "--------------------\n",
      "      Pusheen        ->    fell off    -> surfboard\n",
      "==================================================\n",
      "Sentence: The quick brown fox jumped over the lazy dog .\n",
      "--------------------\n",
      "IE triplets:\n",
      "--------------------\n",
      "  quick brown fox    ->  jumped over   -> lazy dog\n",
      "        fox          ->  jumped over   -> dog\n",
      "  quick brown fox    ->  jumped over   -> dog\n",
      "     quick fox       ->  jumped over   -> dog\n",
      "     brown fox       ->  jumped over   -> lazy dog\n",
      "     brown fox       ->  jumped over   -> dog\n",
      "     quick fox       ->  jumped over   -> lazy dog\n",
      "        fox          ->  jumped over   -> lazy dog\n",
      "==================================================\n",
      "Sentence: Barack Obama was born in Hawaii .\n",
      "--------------------\n",
      "IE triplets:\n",
      "--------------------\n",
      "    Barack Obama     ->      was       -> born\n",
      "    Barack Obama     ->  was born in   -> Hawaii\n",
      "==================================================\n",
      "Sentence: He was elected president in 2008 .\n",
      "--------------------\n",
      "IE triplets:\n",
      "--------------------\n",
      "         He          ->      was       -> elected\n",
      "         He          ->  was elected   -> president\n",
      "         He          -> was elected in -> 2008\n"
     ]
    }
   ],
   "source": [
    "for sentence in output['sentences']:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Sentence: {' '.join([x['word'] for x in sentence['tokens']])}\")\n",
    "    print(\"-\"*20)\n",
    "    print(\"IE triplets:\")\n",
    "    print(\"-\"*20)\n",
    "    for triplet in sentence['openie']:\n",
    "        print(f\"{triplet['subject']:^20} -> {triplet['relation']:^14} -> {triplet['object']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
